{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.1 Scientific computing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "- Computers have become a central tool that is used in virtually every discipline:  \n",
    "\n",
    "    - mathematics\n",
    "    - engineering\n",
    "    - physical sciences\n",
    "    - social sciences\n",
    "    - economics\n",
    "    - data science\n",
    "    - ...\n",
    "\n",
    "- In these disciplines, **mathematical models** are used to explore and gain a deeper understanding of complex systems.\n",
    "\n",
    "- There is now a growing need for those with the ability to develop software that can _efficiently_, _accurately_, and _reliably_ solve mathematical models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this class, we will learn computational methods (algorithms) for working with _continuous_ mathematical models:\n",
    "    \n",
    "| Chapter | Topic |\n",
    "|--------:|-------|\n",
    "|  3 | Nonlinear Equations in One Variable |\n",
    "| 10 | Polynomial Interpolation |\n",
    "| 11 | Piecewise Polynomial Interpolation |\n",
    "| 12 | Best Approximation |\n",
    "| 14 | Numerical Differentiation |\n",
    "| 15 | Numerical Integration |\n",
    "| 16 | Differential Equations |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Learning these algorithms will give you the knowledge and skills to solve more complex problems you may encounter in your careers. We will study:\n",
    "\n",
    "1. The theory behind the algorithms (numerical analysis):\n",
    "    - complexity and convergence rate\n",
    "    - problem conditioning and algorithm stability\n",
    "    - accuracy and error bounds\n",
    "    - proofs\n",
    "2. How to choose which method should be used for a particular problem.\n",
    "3. How to implement the method efficiently.\n",
    "    - We will use [Julia](http://julialang.org): \"a high-level, high-performance dynamic programming language for technical computing.\"\n",
    "    - See [Julia benchmarks](http://julialang.org/benchmarks/) for a comparison with various other languages.\n",
    "4. How to evaluate and test your implementation for *efficiency*, *accuracy*, and *robustness*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1.2: Numerical algorithms and errors\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose some quantity $u$ is approximated by $v$. The **absolute error** is measured by\n",
    "\n",
    "$$\n",
    "|u - v|.\n",
    "$$\n",
    "\n",
    "Often, it is better to look at how large $|u-v|$ is compared to $|u|$. If $|u-v|$ is $p$ percent of $|u|$, then \n",
    "\n",
    "$$\n",
    "|u-v| = p|u|.\n",
    "$$ \n",
    "\n",
    "If $u \\neq 0$, then\n",
    "$$\n",
    "p = \\frac{|u-v|}{|u|},\n",
    "$$\n",
    "which is called the **relative error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = π, 3.14159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(u - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., $\\approx 2.65 \\times 10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = abs(u - v)/abs(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., $\\approx 8.45 \\times 10^{-7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Complete the following table.\n",
    "\n",
    "| $u$ | $v$ | absolute error | relative error |\n",
    "|:---:|:---:|:--------------:|:--------------:|\n",
    "|   1 |  0.99 |  |  |\n",
    "|   1 |  1.5  |  |  |\n",
    "| 100 | 99.99 |  |  |\n",
    "| 100 | 100.5 |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error types\n",
    "\n",
    "1. Errors in mathematical model or in the data\n",
    "2. Approximation errors\n",
    "3. Roundoff errors\n",
    "    - due to the finite precision of real numbers stored on a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation Error (approximating the derivative)\n",
    "\n",
    "Consider the formula for the derivative of a differentiable function $f \\colon \\mathbb{R} \\to \\mathbb{R}$ at $x_0$:\n",
    "\n",
    "$$ f'(x_0) = \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0)}{h}.$$\n",
    "\n",
    "It is therefore reasonable to approximate $f'(x_0)$ using\n",
    "\n",
    "$$\\frac{f(x_0 + h) - f(x_0)}{h}$$\n",
    "\n",
    "for some small positive $h$. The error in this approximation is \n",
    "\n",
    "$$\\left|f'(x_0) - \\frac{f(x_0 + h) - f(x_0)}{h}\\right|$$\n",
    "\n",
    "and is called a **discretization error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Let's computationally examine this approximation error using\n",
    "\n",
    "$$\n",
    "f(x) = \\sin(x) \\quad \\text{and} \\quad x_0 = 1.\n",
    "$$\n",
    "\n",
    "Note that $f'(x) = \\cos(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to define the function $f$ in Julia:\n",
    "```\n",
    "function f(x)\n",
    "    return sin(x)\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "fp = cos(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus \n",
    "\n",
    "$$f'(x_0) = \\cos(1) = 0.5403023058681398\\ldots.$$ \n",
    "\n",
    "Let's write some **Julia** code to approximate this value using \n",
    "\n",
    "$$ \n",
    "f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\n",
    "$$\n",
    "\n",
    "for smaller and smaller values of $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "function foo(f, x0, fp)\n",
    "    h = 1.0\n",
    "    @printf(\"%8s %20s %14s\\n\", \"h\", \"fpapprox\", \"abserr\")\n",
    "    for i in 1:20\n",
    "        fpapprox = (f(x0 + h) - f(x0))/h\n",
    "        abserr = abs(fp - fpapprox)\n",
    "        #println(fpapprox, \"  \", abserr)\n",
    "        @printf(\"%8.1e %20.16f %14.6e\\n\", h, fpapprox, abserr)\n",
    "        h = h/10\n",
    "    end\n",
    "end\n",
    "\n",
    "foo(f, x0, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "fpapprox = 0.5403023028982544\n",
    "fp       = 0.5403023058681398\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Theorem: (Taylor Series)\n",
    "\n",
    "Assume that $f$ is a function that is $(k+1)$-differentiable on an interval containing $x_0$ and $x_0 + h$. Then\n",
    "\n",
    "$$\n",
    "f(x_0 + h) = f(x_0) + h f'(x_0) + \\frac{h^2}{2} f''(x_0) + \\cdots + \\frac{h^k}{k!} f^{(k)}(x_0) + \\frac{h^{k+1}}{(k+1)!} f^{(k+1)}(\\xi),\n",
    "$$\n",
    "\n",
    "for some $\\xi \\in (x_0, x_0 + h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that the discretization error decreases at the same rate as $h$:\n",
    "\n",
    "Solving for $f'(x_0)$ in the Taylor series expansion, we get\n",
    "\n",
    "$$\n",
    "f'(x_0) = \\frac{f(x_0+h)-f(x_0)}{h} - \\left(\\frac{h}{2} f''(x_0) + \\frac{h^2}{6} f'''(x_0)  + \\cdots + \\frac{h^{k-1}}{k!} f^{(k)}(\\xi)\\right).\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\left|f'(x_0) - \\frac{f(x_0+h)-f(x_0)}{h}\\right| = \\left|\\frac{h}{2} f''(x_0) + \\frac{h^2}{6} f'''(x_0) + \\cdots + \\frac{h^{k-1}}{k!} f^{(k)}(\\xi)\\right|.\n",
    "$$\n",
    "\n",
    "If $f''(x_0) \\neq 0$ and $h$ is small, then the right-hand-side is dominated by $\\frac{h}{2} f''(x_0)$. Thus,\n",
    "\n",
    "$$\n",
    "\\left|f'(x_0) - \\frac{f(x_0+h)-f(x_0)}{h}\\right| \\approx \\frac{h}{2}\\left| f''(x_0)\\right| = \\mathcal{O}(h). \\quad \\blacksquare\n",
    "$$\n",
    "\n",
    "(See p. 7 of Ascher-Greif for the rigorous definitions of Big-$\\mathcal{O}$ and $\\Theta$ notation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example continued...\n",
    "\n",
    "Recall that $f(x) = \\sin(x)$. Thus $f''(x) = -\\sin(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpp = -sin(x0)\n",
    "\n",
    "abs(fpp)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-5\n",
    "\n",
    "err = h/2*abs(fpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, \n",
    "$$\n",
    "\\frac{\\left|f''(x_0)\\right|}{2} = 0.42073549240394825\\ldots,\n",
    "$$\n",
    "which agrees very well with our numerical test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "What do you think will happen if $f''(x_0) = 0$? Write code to test your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = cos(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(f, x0, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-3\n",
    "\n",
    "fppp = -cos(x0)\n",
    "\n",
    "err = h^2/6*fppp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff Error\n",
    "\n",
    "Numbers are stored in the computer using a finite precision representation. Roughly 16 digits of precision are possible using the 64-bit floating point format.\n",
    "\n",
    "Whenever an arithmetic operation takes place, the result must be rounded to roughly 16 digits of precision. Such an error is called **roundoff error**.\n",
    "\n",
    "We can see the effect of roundoff error in our example when $h$ is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the [Plots.jl](https://github.com/JuliaPlots/Plots.jl) package to make a plot of $h$ versus the absolute error in this approximation. What do you observe? Why is this happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "f(x) = sin(x)\n",
    "\n",
    "fp = cos(x0)\n",
    "fpp = -sin(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, LaTeXStrings\n",
    "\n",
    "x0 = 1.0\n",
    "\n",
    "h = [10.0^(-x) for x in 0:0.5:20]\n",
    "\n",
    "approx = (f.(x0 .+ h) .- f(x0))./h\n",
    "\n",
    "[h approx]\n",
    "\n",
    "abserr = abs.(fp .- approx)\n",
    "\n",
    "d_err = h*abs(fpp)/2\n",
    "\n",
    "[abserr d_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(h, abserr, xaxis=:log, yaxis=:log, \n",
    "    label=\"abserr\", legend=:bottomleft, marker=:dot)\n",
    "plot!(h, d_err, label=\"d_err\", linestyle=:dash)\n",
    "ylims!(1e-10, 1.0)\n",
    "ylabel!(\"error\")\n",
    "xlabel!(L\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.3 Algorithm properties\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "As we have seen above, it is easy to write *mathematically correct* code that produces very inaccurate results.\n",
    "\n",
    "Accuracy is affected by the following two conditions:\n",
    "\n",
    "1. **Problem conditioning**  \n",
    "    Some problems are highly sensitive to small changes in the input: we call such problems **ill-conditioned**. A problem that is not sensitive to small changes in the input is called **well-conditioned**. For example, computing $\\tan(x)$ for $x$ near $\\pi/2$ is an ill-conditioned problem (**Example 1.5** in Ascher-Greif).\n",
    "2. **Algorithm stability**  \n",
    "    An algorithm is called **stable** if it is guaranteed to produce an exact answer to a *slightly perturbed problem*. (**Example 1.6** in Ascher-Greif gives an example of an **unstable algorithm**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Let \n",
    "\n",
    "$$ y_n = \\int_0^1 \\frac{x^n}{x + 10} dx. $$\n",
    "\n",
    "Show that \n",
    "\n",
    "$$\n",
    "y_n + 10y_{n-1} = \\frac1n\n",
    "$$\n",
    "\n",
    "and that\n",
    "\n",
    "$$\n",
    "y_0 = \\ln(11) - \\ln(10).\n",
    "$$\n",
    "\n",
    "Then use these formulas to numerically compute $y_{30}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = log(11) - log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n = 1:30\n",
    "    y = 1/n - 10*y\n",
    "    println(y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is *very* **unstable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency\n",
    "\n",
    "Efficiency of a code is affected by many factors:\n",
    "\n",
    "1. the rate of convergence of the method\n",
    "2. the number of arithmetic operations performed\n",
    "3. how the data in memory is accessed\n",
    "\n",
    "(See **Example 1.4** in Ascher-Greif for an efficient algorithm for evaluating polynomials: **Horner's rule**.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness (Reliability)\n",
    "\n",
    "We want to ensure that our code works under *all possible inputs*, and generates the clear warnings when it is not possible to produce an accurate result for some input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
